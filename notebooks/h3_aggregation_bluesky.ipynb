{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff62cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from h3 import h3\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, MultiPoint, Polygon\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd2badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode MultiPoint geometries into individual Point rows\n",
    "def explode_multipoints(gdf):\n",
    "    rows = []\n",
    "    for idx, row in tqdm(gdf.iterrows()):\n",
    "        geom = row.geometry\n",
    "        if isinstance(geom, MultiPoint):\n",
    "            for pt in geom.geoms:\n",
    "                new_row = row.copy()\n",
    "                new_row.geometry = pt\n",
    "                rows.append(new_row)\n",
    "        elif isinstance(geom, Point):\n",
    "            rows.append(row)\n",
    "        else:\n",
    "            continue  # skip other geometry types\n",
    "    return gpd.GeoDataFrame(rows, columns=gdf.columns, crs=gdf.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6dda48",
   "metadata": {},
   "source": [
    "Let's aggregate them just spatially:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb63031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105767it [00:13, 7731.22it/s]\n",
      "100%|██████████| 3/3 [02:42<00:00, 54.22s/it]\n"
     ]
    }
   ],
   "source": [
    "for region in [#\"california\", \n",
    "               \"central_europe\"]:\n",
    "\n",
    "    # Load your GeoPackage file\n",
    "    gdf = gpd.read_parquet(f\"Data/bsky_{region}_gdf_esda.parquet\")\n",
    "\n",
    "    # Ensure it's using WGS84 (latitude/longitude) coordinates\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    # explode multipoints\n",
    "    gdf_points = explode_multipoints(gdf)\n",
    "\n",
    "    gdf_points_relevant = gdf_points[gdf_points['disaster_related'] == 1]\n",
    "    \n",
    "    for h3_level in tqdm([4, 5, 6]): \n",
    "        h3_grid = gpd.read_file(f\"Data/h3 grids/h3_{region}_level_{h3_level}.gpkg\")\n",
    "        h3_grid = h3_grid.to_crs(4326)\n",
    "\n",
    "        # Perform spatial join (use 'inner' join to avoid NaNs initially)\n",
    "        joined = gpd.sjoin(gdf_points, h3_grid, how='inner', predicate='intersects')\n",
    "        joined_relevant = gpd.sjoin(gdf_points_relevant, h3_grid, how='inner', predicate='intersects')\n",
    "\n",
    "        # Count number of points per H3 cell\n",
    "        counts = joined.groupby(\"H3HASH\").size().reset_index(name='count')\n",
    "        counts_relevant = joined_relevant.groupby(\"H3HASH\").size().reset_index(name='count')\n",
    "\n",
    "        # Join with original H3 geometries (outer join to keep all grid cells)\n",
    "        post_aggregated = h3_grid.merge(counts, on='H3HASH', how='left')\n",
    "        post_aggregated_relevant = h3_grid.merge(counts_relevant, on='H3HASH', how='left')\n",
    "\n",
    "        # Fill empty grid cells with zero\n",
    "        post_aggregated['count'] = post_aggregated['count'].fillna(0).astype(int)\n",
    "        post_aggregated_relevant['count'] = post_aggregated_relevant['count'].fillna(0).astype(int)\n",
    "\n",
    "        # Save to GeoPackage\n",
    "        post_aggregated.to_crs(epsg=3857).to_file(\n",
    "            f\"Results/bluesky_posts_{region}_h3_level_{h3_level}.gpkg\", \n",
    "            driver=\"GPKG\"\n",
    "        )\n",
    "\n",
    "        post_aggregated_relevant.to_crs(epsg=3857).to_file(\n",
    "            f\"Results/bluesky_relevant_posts_{region}_h3_level_{h3_level}.gpkg\", \n",
    "            driver=\"GPKG\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc78741",
   "metadata": {},
   "source": [
    "Let's also consider time by dividing the dataframe on a weekly basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2379146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "570570it [01:45, 5419.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cid</th>\n",
       "      <th>uri</th>\n",
       "      <th>author_displayName</th>\n",
       "      <th>author_handle</th>\n",
       "      <th>author_did</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>langs</th>\n",
       "      <th>text</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>repostCount</th>\n",
       "      <th>...</th>\n",
       "      <th>p_fear</th>\n",
       "      <th>p_joy</th>\n",
       "      <th>p_sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>no_emotion</th>\n",
       "      <th>disaster_related</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bafyreiai5hex6t2wr2npiuy5ql5lnsfjacemieu6cjjta...</td>\n",
       "      <td>at://did:plc:2amx7tvyqv2nxfqvp5ycskmr/app.bsky...</td>\n",
       "      <td>Muneeb</td>\n",
       "      <td>viralltoday.com</td>\n",
       "      <td>did:plc:2amx7tvyqv2nxfqvp5ycskmr</td>\n",
       "      <td>2024-12-24 00:26:53+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Santa Cruz wharf section collapses, sending 3 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590658</td>\n",
       "      <td>0.046475</td>\n",
       "      <td>0.321727</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bafyreiai5hex6t2wr2npiuy5ql5lnsfjacemieu6cjjta...</td>\n",
       "      <td>at://did:plc:2amx7tvyqv2nxfqvp5ycskmr/app.bsky...</td>\n",
       "      <td>Muneeb</td>\n",
       "      <td>viralltoday.com</td>\n",
       "      <td>did:plc:2amx7tvyqv2nxfqvp5ycskmr</td>\n",
       "      <td>2024-12-24 00:26:53+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Santa Cruz wharf section collapses, sending 3 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590658</td>\n",
       "      <td>0.046475</td>\n",
       "      <td>0.321727</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bafyreiai5hex6t2wr2npiuy5ql5lnsfjacemieu6cjjta...</td>\n",
       "      <td>at://did:plc:2amx7tvyqv2nxfqvp5ycskmr/app.bsky...</td>\n",
       "      <td>Muneeb</td>\n",
       "      <td>viralltoday.com</td>\n",
       "      <td>did:plc:2amx7tvyqv2nxfqvp5ycskmr</td>\n",
       "      <td>2024-12-24 00:26:53+00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>Santa Cruz wharf section collapses, sending 3 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590658</td>\n",
       "      <td>0.046475</td>\n",
       "      <td>0.321727</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bafyreigljnz5z2d5te2t4nvoh5gd7cjspxgijxlzuhxwv...</td>\n",
       "      <td>at://did:plc:jwmyh3wycmjqf4cav3e5iazu/app.bsky...</td>\n",
       "      <td>DJ Black</td>\n",
       "      <td>djblack21.bsky.social</td>\n",
       "      <td>did:plc:jwmyh3wycmjqf4cav3e5iazu</td>\n",
       "      <td>2024-12-24 00:25:53.210000+00:00</td>\n",
       "      <td>[en]</td>\n",
       "      <td>It happened around 12:45 p.m. Monday at Santa ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646496</td>\n",
       "      <td>0.037827</td>\n",
       "      <td>0.190053</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>bafyreih7lxoxueby4hdcbiuu33kjimoxr5dlny7ebgvt6...</td>\n",
       "      <td>at://did:plc:ykbvqikdxucwe4hsmbzltrbk/app.bsky...</td>\n",
       "      <td></td>\n",
       "      <td>butterfliesfree.bsky.social</td>\n",
       "      <td>did:plc:ykbvqikdxucwe4hsmbzltrbk</td>\n",
       "      <td>2024-12-24 00:24:42.005000+00:00</td>\n",
       "      <td>[da]</td>\n",
       "      <td>Victoria prepares for worst fire conditions si...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.030460</td>\n",
       "      <td>0.059179</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  cid  \\\n",
       "15  bafyreiai5hex6t2wr2npiuy5ql5lnsfjacemieu6cjjta...   \n",
       "15  bafyreiai5hex6t2wr2npiuy5ql5lnsfjacemieu6cjjta...   \n",
       "15  bafyreiai5hex6t2wr2npiuy5ql5lnsfjacemieu6cjjta...   \n",
       "29  bafyreigljnz5z2d5te2t4nvoh5gd7cjspxgijxlzuhxwv...   \n",
       "37  bafyreih7lxoxueby4hdcbiuu33kjimoxr5dlny7ebgvt6...   \n",
       "\n",
       "                                                  uri author_displayName  \\\n",
       "15  at://did:plc:2amx7tvyqv2nxfqvp5ycskmr/app.bsky...             Muneeb   \n",
       "15  at://did:plc:2amx7tvyqv2nxfqvp5ycskmr/app.bsky...             Muneeb   \n",
       "15  at://did:plc:2amx7tvyqv2nxfqvp5ycskmr/app.bsky...             Muneeb   \n",
       "29  at://did:plc:jwmyh3wycmjqf4cav3e5iazu/app.bsky...           DJ Black   \n",
       "37  at://did:plc:ykbvqikdxucwe4hsmbzltrbk/app.bsky...                      \n",
       "\n",
       "                  author_handle                        author_did  \\\n",
       "15              viralltoday.com  did:plc:2amx7tvyqv2nxfqvp5ycskmr   \n",
       "15              viralltoday.com  did:plc:2amx7tvyqv2nxfqvp5ycskmr   \n",
       "15              viralltoday.com  did:plc:2amx7tvyqv2nxfqvp5ycskmr   \n",
       "29        djblack21.bsky.social  did:plc:jwmyh3wycmjqf4cav3e5iazu   \n",
       "37  butterfliesfree.bsky.social  did:plc:ykbvqikdxucwe4hsmbzltrbk   \n",
       "\n",
       "                          createdAt langs  \\\n",
       "15        2024-12-24 00:26:53+00:00  None   \n",
       "15        2024-12-24 00:26:53+00:00  None   \n",
       "15        2024-12-24 00:26:53+00:00  None   \n",
       "29 2024-12-24 00:25:53.210000+00:00  [en]   \n",
       "37 2024-12-24 00:24:42.005000+00:00  [da]   \n",
       "\n",
       "                                                 text  replyCount  \\\n",
       "15  Santa Cruz wharf section collapses, sending 3 ...           0   \n",
       "15  Santa Cruz wharf section collapses, sending 3 ...           0   \n",
       "15  Santa Cruz wharf section collapses, sending 3 ...           0   \n",
       "29  It happened around 12:45 p.m. Monday at Santa ...           0   \n",
       "37  Victoria prepares for worst fire conditions si...           0   \n",
       "\n",
       "    repostCount  ...    p_fear     p_joy p_sadness  anger   fear    joy  \\\n",
       "15            0  ...  0.590658  0.046475  0.321727  False   True  False   \n",
       "15            0  ...  0.590658  0.046475  0.321727  False   True  False   \n",
       "15            0  ...  0.590658  0.046475  0.321727  False   True  False   \n",
       "29            1  ...  0.646496  0.037827  0.190053  False   True  False   \n",
       "37            0  ...  0.387715  0.030460  0.059179   True  False  False   \n",
       "\n",
       "   sadness no_emotion disaster_related week  \n",
       "15   False      False                1   52  \n",
       "15   False      False                1   52  \n",
       "15   False      False                1   52  \n",
       "29   False      False                1   52  \n",
       "37   False      False                1   52  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:58<00:00, 89.25s/it]\n"
     ]
    }
   ],
   "source": [
    "for region in [\"california\", \n",
    "            #    \"central_europe\"\n",
    "               ]:\n",
    "\n",
    "    # Load your GeoPackage file\n",
    "    gdf = gpd.read_parquet(f\"Data/bsky_{region}_gdf_esda.parquet\")\n",
    "\n",
    "    # Ensure it's using WGS84 (latitude/longitude) coordinates\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    # explode multipoints\n",
    "    gdf_points = explode_multipoints(gdf)\n",
    "\n",
    "    # Add a week number column based on a datetime column\n",
    "    gdf_points['createdAt'] = pd.to_datetime(gdf_points['createdAt'], utc=True)\n",
    "    gdf_points['week'] = pd.to_datetime(gdf_points['createdAt']).dt.isocalendar().week\n",
    "\n",
    "    gdf_points_relevant = gdf_points[gdf_points['disaster_related'] == 1]\n",
    "    \n",
    "    for h3_level in tqdm([4, 5]): \n",
    "        h3_grid = gpd.read_file(f\"Data/h3 grids/h3_{region}_level_{h3_level}.gpkg\")\n",
    "        h3_grid = h3_grid.to_crs(4326)\n",
    "\n",
    "        for week_number in sorted(gdf_points['week'].unique()):\n",
    "            week_points = gdf_points[gdf_points['week'] == week_number]\n",
    "            week_relevant_points = gdf_points_relevant[gdf_points_relevant['week'] == week_number]\n",
    "\n",
    "            # Spatial join\n",
    "            joined = gpd.sjoin(week_points, h3_grid, how='inner', predicate='intersects')\n",
    "            joined_relevant = gpd.sjoin(week_relevant_points, h3_grid, how='inner', predicate='intersects')\n",
    "\n",
    "            # Count points per H3 cell\n",
    "            counts = joined.groupby(\"H3HASH\").size().reset_index(name='count')\n",
    "            counts_relevant = joined_relevant.groupby(\"H3HASH\").size().reset_index(name='count')\n",
    "\n",
    "            # Merge with grid\n",
    "            post_aggregated = h3_grid.merge(counts, on='H3HASH', how='left')\n",
    "            post_aggregated_relevant = h3_grid.merge(counts_relevant, on='H3HASH', how='left')\n",
    "\n",
    "            # Fill NaNs\n",
    "            post_aggregated['count'] = post_aggregated['count'].fillna(0).astype(int)\n",
    "            post_aggregated_relevant['count'] = post_aggregated_relevant['count'].fillna(0).astype(int)\n",
    "\n",
    "            # Save with week suffix\n",
    "            post_aggregated.to_crs(epsg=3857).to_file(\n",
    "                f\"Results/weekly/bluesky_posts_{region}_h3_level_{h3_level}_week_{week_number}.gpkg\", \n",
    "                driver=\"GPKG\"\n",
    "            )\n",
    "\n",
    "            post_aggregated_relevant.to_crs(epsg=3857).to_file(\n",
    "                f\"Results/weekly/bluesky_relevant_posts_{region}_h3_level_{h3_level}_week_{week_number}.gpkg\", \n",
    "                driver=\"GPKG\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geodata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
